{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116c1c8-81ab-4f5a-a341-fd3733a7b608",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:03:49.352414Z",
     "iopub.status.busy": "2025-05-14T03:03:49.352261Z",
     "iopub.status.idle": "2025-05-14T03:03:49.970018Z",
     "shell.execute_reply": "2025-05-14T03:03:49.969388Z",
     "shell.execute_reply.started": "2025-05-14T03:03:49.352396Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lecode_util.call_llm import ask_tyqw,ask_llm\n",
    "\n",
    "keyfact_Evaluation_PROMPT_cot = \"\"\"分析用户-律师咨询对话中提及的关键信息，并将其与给定的关键信息列表进行匹配。\n",
    "输入数据：\n",
    "1. 用户-律师对话 (user_lawyer_dialogue):\n",
    "   - 格式为：{对话ID: {'q': 问题, 'a': 回答}}\n",
    "   - 每组对话包含律师提问和用户回答\n",
    "\n",
    "2. 关键信息列表 (key_information_li):\n",
    "   - 格式为：{序号: 信息内容}\n",
    "   - 序号从0开始\n",
    "\n",
    "任务要求：\n",
    "1. 识别对话中出现的关键信息\n",
    "2. 将识别到的信息与关键信息列表中的条目进行匹配\n",
    "3. 记录匹配信息的序号\n",
    "\n",
    "输出格式要求：\n",
    "- 输出应为一个 Python 字典\n",
    "- 键：对话ID (如 \"QA0\", \"QA1\"...)\n",
    "- 值：该对话中提及的关键信息序号列表\n",
    "- 如果没有任何关键信息被提及，则返回一个空字典{}。\n",
    "- 示例格式：\n",
    "```python\n",
    "{\"QA0\":[0,1],\"QA1\":2,...}\n",
    "```\n",
    "\n",
    "以下是咨询对话和关键信息列表:\n",
    "[咨询对话]\n",
    "{user_lawyer_dialogue}\n",
    "\n",
    "[关键信息列表]\n",
    "{key_information_li}\n",
    "\n",
    "Let's think step by step:\n",
    "\"\"\"\n",
    "keyfact_Evaluation_PROMPT_nocot = \"\"\"分析用户-律师咨询对话中提及的关键信息，并将其与给定的关键信息列表进行匹配。\n",
    "输入数据：\n",
    "1. 用户-律师对话 (user_lawyer_dialogue):\n",
    "   - 格式为：{对话ID: {'q': 问题, 'a': 回答}}\n",
    "   - 每组对话包含律师提问和用户回答\n",
    "\n",
    "2. 关键信息列表 (key_information_li):\n",
    "   - 格式为：{序号: 信息内容}\n",
    "   - 序号从0开始\n",
    "\n",
    "任务要求：\n",
    "1. 识别对话中出现的关键信息\n",
    "2. 将识别到的信息与关键信息列表中的条目进行匹配\n",
    "3. 记录匹配信息的序号\n",
    "\n",
    "输出格式要求：\n",
    "- 输出应为一个 Python 字典\n",
    "- 键：对话ID (如 \"QA0\", \"QA1\"...)\n",
    "- 值：该对话中提及的关键信息序号列表\n",
    "- 如果没有任何关键信息被提及，则返回一个空字典{}。\n",
    "- 示例格式：\n",
    "```python\n",
    "{\"QA0\":[0,1],\"QA1\":2,...}\n",
    "```\n",
    "\n",
    "以下是咨询对话和关键信息列表:\n",
    "[咨询对话]\n",
    "{user_lawyer_dialogue}\n",
    "\n",
    "[关键信息列表]\n",
    "{key_information_li}\n",
    "\n",
    "- 仅输出结果，不要有任何思考过程\n",
    "\"\"\"\n",
    "\n",
    "suggestion_evaluation_prompt = \"\"\"你是一位经验丰富的法律专家，专门评估法律咨询对话的法律建议的质量。请以公正、严谨的评判者身份，对AI助手提供的法律建议的质量进行客观评估。在评估时，请从以下五个关键维度进行分析和评分：\n",
    "\n",
    "1.专业性\n",
    "- 准确理解客户的问题并提供相关答案\n",
    "- 清晰简洁地解释复杂的法律知识\n",
    "- 建议的可操作性\n",
    "2.流畅性\n",
    "- 确保语义连贯性，没有逻辑错误或不相关的信息\n",
    "- 保持风格和内容的一致性\n",
    "- 保持友好、热情的回答态度\n",
    "3.完整性\n",
    "- 提供了足够的信息和细节\n",
    "- 没有遗漏重要的建议\n",
    "4.服务性\n",
    "- 回应的针对性，提供个性化的解决方案\n",
    "- 使用平易近人的表达方式，语言的亲和度\n",
    "- 注重客户体验和感受,对当事人诉求的共情与尊重\n",
    "5.安全性\n",
    "- 提供科学、准确的法律知识。\n",
    "- 确保客户安全;拒绝可能造成伤害的信息或建议。\n",
    "- 遵守职业道德并尊重客户的选择。不得包含歧视性、偏见性或有害内容。\n",
    "\n",
    "我们将提供以下材料: 高质量的参考答案, AI助手撰写的法律建议。\n",
    "在开始评估时，你需要遵循以下推理步骤：\n",
    "1. 比较AI助手撰写的法律建议与参考答案，指出AI助手答案中的不足之处，并详细解释。 \n",
    "2. 根据上述维度评估AI助手的法律建议，每个维度给出1到10分的分数。\n",
    "3. 基于各维度的得分，得出AI助手的综合评分（1-10分）。\n",
    "4. 你的评分应尽可能严格，并且必须遵循以下评分规则：回复的质量越高，得分越高。\n",
    " \n",
    "评分标准：\n",
    "1-2分：建议包含与案件无关内容，存在严重错误，包含未经验证或虚假信息，或产生具有潜在危害的内容。\n",
    "3-4分：建议无重大错误，但在法律关系界定或关键点回应上存在明显不足，逻辑推理较差，缺乏针对性,建议过于笼统，未达到基本咨询要求。\n",
    "5-6分：建议基本符合咨询要求，法律分析准确但逻辑完整性一般，基本回应了咨询要点但缺乏深度分析，整体表现中规中矩。\n",
    "7-8分：建议质量接近参考答案，供了切实可行的解决方案，各评估维度表现优秀，无明显缺陷。\n",
    "9-10分：建议质量显著超越参考答案，各维度表现近乎完美，提供了极具价值的解决方案。\n",
    "  \n",
    "  \n",
    "评分时请提供详细的评估注释。在每个维度分数后，请务必提供解释。所有分数都应为整数。最后，以以下字典格式返回评估结果：\n",
    " \n",
    "```python{{'专业性': 分数, '流畅性': 分数, '完整性': 分数, '服务性': 分数, '安全性': 分数, '综合得分': 总分}}```\n",
    " \n",
    "<法律咨询对话>\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "</法律咨询对话>\n",
    "\n",
    "<参考答案>\n",
    " \n",
    "{gt_suggestion}\n",
    " \n",
    "</参考答案>\n",
    "\n",
    "<AI Assistant待评估建议>\n",
    " \n",
    "{pred_suggestion}\n",
    " \n",
    "</AI Assistant待评估建议>\n",
    " \n",
    "请开始评估：\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import re\n",
    "# 使用正则表达式提取内容\n",
    "def extract_python(text):\n",
    "    if \"```python\" in text:\n",
    "        pattern = r'```python\\n(.*?)\\n```'\n",
    "\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            extracted_content = match.group(1)\n",
    "\n",
    "            return True,eval(extracted_content)\n",
    "        else:\n",
    "            return  False,None\n",
    "    else:\n",
    "        try:\n",
    "            return True,eval(text)\n",
    "        except:\n",
    "            return  False,None\n",
    "def count_key_fact_num(llm_keyfact_dict):\n",
    "    if llm_keyfact_dict==str:\n",
    "        llm_keyfact_dict =eval(llm_keyfact_dict)\n",
    "    if len(llm_keyfact_dict) ==0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        res_ = []\n",
    "        for k in llm_keyfact_dict:\n",
    "            res_.extend(llm_keyfact_dict[k])\n",
    "        return len(set(res_))\n",
    "def compute_recall5(num):\n",
    "    try:\n",
    "        if type(df['llm_evaluate_keyfact'][num]) ==str:\n",
    "            res_dict = eval(df['llm_evaluate_keyfact'][num])\n",
    "        else:\n",
    "            res_dict = df['llm_evaluate_keyfact'][num]\n",
    "        res_set = []\n",
    "        for k in res_dict:\n",
    "            if k <5:\n",
    "                res_set.extend(res_dict[k])\n",
    "        res_set = set(res_set) \n",
    "        # importance = dict((int(k), v) for k, v in eval(df['gt_key_fact_importance'][num]).items())\n",
    "        len_key = len(eval(df['gt_key_fact_importance'][num]))\n",
    "\n",
    "\n",
    "        return len(res_set)/len_key\n",
    "    except:\n",
    "        \n",
    "        return None\n",
    "def compute_weighted_recall(num):\n",
    "    try:\n",
    "        # res_dict = eval(df['llm_evaluate_keyfact'][num])\n",
    "        if type(df['llm_evaluate_keyfact'][num]) ==str:\n",
    "            res_dict = eval(df['llm_evaluate_keyfact'][num])\n",
    "        else:\n",
    "            res_dict = df['llm_evaluate_keyfact'][num]\n",
    "        res_set = []\n",
    "        for k in res_dict:\n",
    "            res_set.extend(res_dict[k])\n",
    "        res_set = set(res_set) \n",
    "        importance = dict((int(k), v) for k, v in eval(df['gt_key_fact_importance'][num]).items())\n",
    "\n",
    "        all_weight = sum(importance.values())\n",
    "        recall_weight = sum([importance[i] for i in res_set])\n",
    "\n",
    "        return recall_weight/all_weight\n",
    "    except:\n",
    "        \n",
    "        return None\n",
    "import math\n",
    "def compute_ndcg(num):\n",
    "    # 用于记录 key fact 的id 是否出现过，只统计最先出现的\n",
    "    try:\n",
    "        existed_li = []\n",
    "        if type(df['llm_evaluate_keyfact'][num]) ==str:\n",
    "            res_dict = eval(df['llm_evaluate_keyfact'][num])\n",
    "        else:\n",
    "            res_dict = df['llm_evaluate_keyfact'][num]\n",
    "        # print(res_dict)\n",
    "        importance = dict((int(k), v) for k, v in eval(df['gt_key_fact_importance'][num]).items())\n",
    "        # print(importance)\n",
    "        importance_dict = {}\n",
    "        for query_id in res_dict:\n",
    "            importance_v = 0\n",
    "            for val in res_dict[query_id]: # 循环每一个key fact id （val）\n",
    "\n",
    "                if val not in existed_li:\n",
    "                    existed_li.append(val) # 将统计过了的放入existedli\n",
    "                    importance_v = importance_v+importance[val] #--> 对应 key fact的相关性\n",
    "                int(query_id)+1 # --> 对应的位置\n",
    "            importance_dict[int(query_id)+1] = importance_v\n",
    "        DCG = 0\n",
    "        # print(importance_dict)\n",
    "        for k,v in importance_dict.items():\n",
    "            DCG = DCG + v/math.log(k+1,2)\n",
    "        # print(DCG)\n",
    "        iDCG = 0\n",
    "        for idx, v in enumerate(sorted(list(importance_dict.values()),reverse=True)):\n",
    "            iDCG = iDCG+ v/math.log(idx+1+1,2)\n",
    "        if iDCG == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return DCG/iDCG\n",
    "    except:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "def process_dialogue(num,model_name='qwen-max'):\n",
    "    pred_diag = eval(df['pred_dialogue'][num])[1:-1]\n",
    "    pred_diag = [[i[0],i[1].replace(\"提问:\",\"\").replace(\"用户:\",\"\").replace(\"不知道。\",\"不知道\")] for i in pred_diag]\n",
    "\n",
    "\n",
    "    # 在转换时记录原始索引\n",
    "    qa_pairs = []\n",
    "    for i in range(0, len(pred_diag), 2):\n",
    "        if i+1 < len(pred_diag):  # 确保有问答对\n",
    "            qa_pair = {\n",
    "                'q': pred_diag[i][1],      # 律师的问题\n",
    "                'a': pred_diag[i+1][1],    # 用户的回答\n",
    "                'original_idx': i//2        # 记录原始索引位置\n",
    "            }\n",
    "            qa_pairs.append(qa_pair)\n",
    "\n",
    "    # 过滤掉\"不知道\"的回答并保持原始索引\n",
    "    filtered_qa = [qa for qa in qa_pairs if qa['a'] != '不知道']\n",
    "\n",
    "    # 转换为numbered字典\n",
    "    numbered_qa = {f\"QA{i}\": qa for i, qa in enumerate(filtered_qa)}\n",
    "\n",
    "\n",
    "    user_lawyer_dialogue = {}\n",
    "    for idx, qa in numbered_qa.items():\n",
    "        user_lawyer_dialogue[idx] = {\n",
    "            '律师': qa['q'],\n",
    "            '用户': qa['a']\n",
    "        }\n",
    "        \n",
    "    gt_key_fact = eval(df['gt_key_fact'][num])\n",
    "    gt_key_fact = dict((int(k), v) for k, v in gt_key_fact.items())\n",
    "\n",
    "    response, usage = ask_llm(keyfact_Evaluation_PROMPT_nocot.replace(\"{user_lawyer_dialogue}\",str(user_lawyer_dialogue)).replace(\"{key_information_li}\",str(gt_key_fact)),model=model_name)\n",
    "    \n",
    "    flag,result = extract_python(response)\n",
    "    \n",
    "    final_res = {}\n",
    "    for key in result:\n",
    "        final_res[numbered_qa[key][\"original_idx\"]] = result[key]\n",
    "        \n",
    "    if flag:\n",
    "        return final_res\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def process_suggestion(num,model_name='gpt-4o-mini'):\n",
    "\n",
    "    response, usage = ask_llm(suggestion_evaluation_prompt.replace(\"{gt_suggestion}\",df['gt_suggestion'][num]).replace(\"{pred_suggestion}\",df['pred_suggestion'][num]).replace(\"{dialogue}\",df['pred_dialogue'][num])\n",
    "                              ,model=model_name)\n",
    "        \n",
    "    return response\n",
    "\n",
    "    \n",
    "import re\n",
    "import ast\n",
    "\n",
    "def check_suggestion_format(text):\n",
    "    # 首先检查是否包含```python{...}```格式\n",
    "    pattern = r'```python\\s*({[^}]+})\\s*```'\n",
    "    match = re.search(pattern, text)\n",
    "    if not match:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # 提取字典字符串并转换为Python对象\n",
    "        dict_str = match.group(1)\n",
    "        dict_obj = ast.literal_eval(dict_str)\n",
    "        \n",
    "        # 检查是否是字典类型\n",
    "        if not isinstance(dict_obj, dict):\n",
    "            return False\n",
    "        \n",
    "        # 必需的键\n",
    "        required_keys = {'专业性', '流畅性', '完整性', '服务性', '安全性', '综合得分'}\n",
    "        \n",
    "        # 检查键是否完全匹配\n",
    "        if set(dict_obj.keys()) != required_keys:\n",
    "            return False\n",
    "        \n",
    "        # 检查所有值是否都是1-10的整数\n",
    "        for value in dict_obj.values():\n",
    "            if not isinstance(value, int) or value < 1 or value > 10:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except (ValueError, SyntaxError):\n",
    "        return False\n",
    "def extract_python_2(text):\n",
    "    if \"```python\" in text:\n",
    "        pattern = r'```python(.*?)```'\n",
    "\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            extracted_content = match.group(1)\n",
    "\n",
    "            return True,eval(extracted_content)\n",
    "        else:\n",
    "            return  False,None\n",
    "    else:\n",
    "        try:\n",
    "            return True,eval(text)\n",
    "        except:\n",
    "            return  False,None\n",
    "\n",
    "def extract_suggestion_rate(text):\n",
    "    _,score_dict = extract_python_2(text)\n",
    "    return score_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fbba3c-5961-4d7b-85ba-e6831b2669cb",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:03:57.239459Z",
     "iopub.status.busy": "2025-05-14T03:03:57.238782Z",
     "iopub.status.idle": "2025-05-14T03:03:57.715550Z",
     "shell.execute_reply": "2025-05-14T03:03:57.715001Z",
     "shell.execute_reply.started": "2025-05-14T03:03:57.239435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path =\"output_file_ask_q\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"outputs/evaluation_output/{path}.csv\")\n",
    "\n",
    "\n",
    "mode_type=\"concurrent\" # 选择并行来评估\n",
    "# mode_type=\"sequence\" # 选择一条一条数据来评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcb5e9-bb7e-44aa-902f-786aa662941c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7397898-5eb3-4723-b573-6267507fed73",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:03:59.447931Z",
     "iopub.status.busy": "2025-05-14T03:03:59.447202Z",
     "iopub.status.idle": "2025-05-14T03:09:18.491992Z",
     "shell.execute_reply": "2025-05-14T03:09:18.491312Z",
     "shell.execute_reply.started": "2025-05-14T03:03:59.447899Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "if mode_type ==\"sequence\":\n",
    "    final_res = []\n",
    "    error_li = []\n",
    "    for num in tqdm(range(0,len(df))):\n",
    "        res = process_dialogue(num)\n",
    "        if res !=False:\n",
    "            final_res.append(res)\n",
    "        else:\n",
    "            final_res.append(None)\n",
    "            error_li.append(num)\n",
    "elif mode_type==\"concurrent\":\n",
    "    num_workers = 32*3  # 可以根据需求调整\n",
    "\n",
    "    final_res = [None] * len(df)  # 预分配列表\n",
    "    error_li = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # 提交所有任务\n",
    "        future_to_idx = {\n",
    "            executor.submit(process_dialogue, i): i \n",
    "            for i in range(len(df))\n",
    "        }\n",
    "\n",
    "        # 使用tqdm显示进度\n",
    "        for future in tqdm(\n",
    "            as_completed(future_to_idx),  # 使用 as_completed 而不是 concurrent.futures.as_completed\n",
    "            total=len(df),\n",
    "            desc=\"Processing\"\n",
    "        ):\n",
    "            idx = future_to_idx[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result != False:\n",
    "                    final_res[idx] = result\n",
    "                else:\n",
    "                    final_res[idx] = None\n",
    "                    error_li.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing index {idx}: {str(e)}\")\n",
    "                error_li.append(idx)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e1dba3-3fb9-4078-8623-99f37bbfec72",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:11:33.824981Z",
     "iopub.status.busy": "2025-05-14T03:11:33.824398Z",
     "iopub.status.idle": "2025-05-14T03:11:33.828158Z",
     "shell.execute_reply": "2025-05-14T03:11:33.827589Z",
     "shell.execute_reply.started": "2025-05-14T03:11:33.824955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_li = [idx for idx,i in enumerate(final_res) if i==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303efb8e-aea0-4faf-930e-6987bd7f0e4a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:11:35.939040Z",
     "iopub.status.busy": "2025-05-14T03:11:35.938185Z",
     "iopub.status.idle": "2025-05-14T03:11:46.329433Z",
     "shell.execute_reply": "2025-05-14T03:11:46.328791Z",
     "shell.execute_reply.started": "2025-05-14T03:11:35.939017Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 6/6 [00:10<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "error_li_1 =[]\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # 提交所有任务\n",
    "    future_to_idx = {\n",
    "        executor.submit(process_dialogue, i): i \n",
    "        for i in error_li\n",
    "    }\n",
    "\n",
    "    # 使用tqdm显示进度\n",
    "    for future in tqdm(\n",
    "        as_completed(future_to_idx),  # 使用 as_completed 而不是 concurrent.futures.as_completed\n",
    "        total=len(error_li),\n",
    "        desc=\"Processing\"\n",
    "    ):\n",
    "        idx = future_to_idx[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result != False:\n",
    "                final_res[idx] = result\n",
    "            else:\n",
    "                final_res[idx] = None\n",
    "                error_li_1.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {idx}: {str(e)}\")\n",
    "            error_li_1.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf8494-d6cf-4e67-b4c6-47083cdb5557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T03:11:54.765626Z",
     "iopub.status.busy": "2025-05-14T03:11:54.765055Z",
     "iopub.status.idle": "2025-05-14T03:11:54.951215Z",
     "shell.execute_reply": "2025-05-14T03:11:54.950687Z",
     "shell.execute_reply.started": "2025-05-14T03:11:54.765604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"llm_evaluate_keyfact\"] = final_res\n",
    "\n",
    "df[\"llm_evaluate_keyfact_num\"] = df[\"llm_evaluate_keyfact\"].apply(count_key_fact_num)\n",
    "# df\n",
    "df[\"llm_evaluate_keyfact_recall\"] = df[\"llm_evaluate_keyfact_num\"]/df['gt_key_fact'].apply(eval).apply(len)\n",
    "df[\"llm_evaluate_keyfact_precision\"] = df[\"llm_evaluate_keyfact_num\"]/(df['pred_dialogue'].apply(eval).apply(len)-2)/2\n",
    "\n",
    "# 计算recall at 5\n",
    "recall5 = []\n",
    "for num in range(0,len(df)):\n",
    "    recall5.append(compute_recall5(num))\n",
    "df['recall@5'] = recall5\n",
    "#计算weighted recall\n",
    "weighted_recall = []\n",
    "for num in range(0,len(df)):\n",
    "    weighted_recall.append(compute_weighted_recall(num))\n",
    "df['weighted_recall'] = weighted_recall\n",
    "# 计算ndcg\n",
    "ndcg_li = []\n",
    "for num in range(0,len(df)):\n",
    "    ndcg_li.append(compute_ndcg(num))\n",
    "df['ndcg'] = ndcg_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81513f88-71fe-42b5-832e-2baba06bc66f",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T09:42:31.897078Z",
     "iopub.status.busy": "2025-05-14T09:42:31.896463Z",
     "iopub.status.idle": "2025-05-14T09:42:31.900277Z",
     "shell.execute_reply": "2025-05-14T09:42:31.899772Z",
     "shell.execute_reply.started": "2025-05-14T09:42:31.897050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "if mode_type ==\"sequence\":\n",
    "    final_res_suggestion = []\n",
    "    error_li_suggestion = []\n",
    "    for num in tqdm(range(0,len(df))):\n",
    "        res = process_suggestion(num)\n",
    "\n",
    "        final_res_suggestion.append(res)\n",
    "\n",
    "elif mode_type==\"concurrent\":\n",
    "    # 可以设置更多的线程数，因为IO操作不受GIL限制\n",
    "    # num_workers = 32*3  # 可以根据需求调整\n",
    "    num_workers=45\n",
    "    final_res_suggestion = [None] * len(df)  # 预分配列表\n",
    "    error_li_suggestion = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # 提交所有任务\n",
    "        future_to_idx = {\n",
    "            executor.submit(process_suggestion, i): i \n",
    "            for i in range(len(df))\n",
    "        }\n",
    "\n",
    "        # 使用tqdm显示进度\n",
    "        for future in tqdm(\n",
    "            as_completed(future_to_idx),  # 使用 as_completed 而不是 concurrent.futures.as_completed\n",
    "            total=len(df),\n",
    "            desc=\"Processing\"\n",
    "        ):\n",
    "            idx = future_to_idx[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result != False:\n",
    "                    final_res_suggestion[idx] = result\n",
    "                else:\n",
    "                    final_res_suggestion[idx] = None\n",
    "                    error_li_suggestion.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing index {idx}: {str(e)}\")\n",
    "                error_li_suggestion.append(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d79ef81-2d77-486b-a784-d12f6f07cc76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T03:21:02.935213Z",
     "iopub.status.busy": "2025-05-14T03:21:02.934211Z",
     "iopub.status.idle": "2025-05-14T03:21:59.084857Z",
     "shell.execute_reply": "2025-05-14T03:21:59.084204Z",
     "shell.execute_reply.started": "2025-05-14T03:21:02.935186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 23/23 [00:56<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "error_li_suggestion = []\n",
    "for idx,i in enumerate(final_res_suggestion):\n",
    "    if i!=None:\n",
    "        if not check_suggestion_format(i):\n",
    "            error_li_suggestion.append(idx)\n",
    "    if i==None:\n",
    "        error_li_suggestion.append(idx)\n",
    "        \n",
    "error_li_suggestion_1 =[]\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # 提交所有任务\n",
    "    future_to_idx = {\n",
    "        executor.submit(process_suggestion, i): i \n",
    "        for i in error_li_suggestion\n",
    "    }\n",
    "\n",
    "    # 使用tqdm显示进度\n",
    "    for future in tqdm(\n",
    "        as_completed(future_to_idx),  # 使用 as_completed 而不是 concurrent.futures.as_completed\n",
    "        total=len(error_li_suggestion),\n",
    "        desc=\"Processing\"\n",
    "    ):\n",
    "        idx = future_to_idx[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result != False:\n",
    "                final_res_suggestion[idx] = result\n",
    "            else:\n",
    "                final_res_suggestion[idx] = None\n",
    "                error_li_suggestion_1.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {idx}: {str(e)}\")\n",
    "            error_li_suggestion_1.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ace6b9-1f54-4b69-8d94-aa99baa12a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T03:22:03.165373Z",
     "iopub.status.busy": "2025-05-14T03:22:03.164733Z",
     "iopub.status.idle": "2025-05-14T03:22:03.187538Z",
     "shell.execute_reply": "2025-05-14T03:22:03.186890Z",
     "shell.execute_reply.started": "2025-05-14T03:22:03.165346Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "error_li_suggestion = []\n",
    "for idx,i in enumerate(final_res_suggestion):\n",
    "    if i!=None:\n",
    "        if not check_suggestion_format(i):\n",
    "            error_li_suggestion.append(idx)\n",
    "    if i==None:\n",
    "        error_li_suggestion.append(idx)\n",
    "        \n",
    "print(len(error_li_suggestion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d299993-c21b-494a-9c17-ce829606daea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:22:07.437861Z",
     "iopub.status.busy": "2025-05-14T03:22:07.437331Z",
     "iopub.status.idle": "2025-05-14T03:22:07.460983Z",
     "shell.execute_reply": "2025-05-14T03:22:07.460449Z",
     "shell.execute_reply.started": "2025-05-14T03:22:07.437839Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['suggestion_rate'] = final_res_suggestion\n",
    "df['suggestion_rate_dict'] = df['suggestion_rate'].apply(extract_suggestion_rate)\n",
    "df['专业性'] = df['suggestion_rate_dict'].apply(lambda x: x['专业性'])\n",
    "df['流畅性'] = df['suggestion_rate_dict'].apply(lambda x: x['流畅性'])\n",
    "df['完整性'] = df['suggestion_rate_dict'].apply(lambda x: x['完整性'])\n",
    "df['服务性'] = df['suggestion_rate_dict'].apply(lambda x: x['服务性'])\n",
    "df['安全性'] = df['suggestion_rate_dict'].apply(lambda x: x['安全性'])\n",
    "df['综合得分'] = df['suggestion_rate_dict'].apply(lambda x: x['综合得分'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57a513af-3817-4424-9a35-b00cb62dd1a8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:22:08.936407Z",
     "iopub.status.busy": "2025-05-14T03:22:08.935823Z",
     "iopub.status.idle": "2025-05-14T03:22:09.012290Z",
     "shell.execute_reply": "2025-05-14T03:22:09.011697Z",
     "shell.execute_reply.started": "2025-05-14T03:22:08.936385Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(f\"outputs/evaluation_output/{path}_evalgpt42.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b3ead-6c89-47eb-a6b3-ac3586af5aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c45566e2-b475-433b-96d7-7a2edd3a4a8d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:22:21.091115Z",
     "iopub.status.busy": "2025-05-14T03:22:21.090406Z",
     "iopub.status.idle": "2025-05-14T03:22:21.096491Z",
     "shell.execute_reply": "2025-05-14T03:22:21.096038Z",
     "shell.execute_reply.started": "2025-05-14T03:22:21.091088Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics Summary:\n",
      "--------------------------------------------------\n",
      "llm_evaluate_keyfact_recall\t0.5380\n",
      "weighted_recall\t0.5508\n",
      "recall@5\t0.4345\n",
      "ndcg\t0.8472\n",
      "ask_turn\t20.3649\n",
      "dont_know_num\t0.4705\n",
      "rouge\t0.1848\n",
      "bertscore\t0.6748\n",
      "--------------------------------------------------\n",
      "\n",
      "Excel Format:\n",
      "0.5380\t0.5508\t0.4345\t0.8472\t20.3649\t0.4705\t0.1848\t0.6748\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"llm_evaluate_keyfact_recall\": df['llm_evaluate_keyfact_recall'].mean(),\n",
    "    \"weighted_recall\": df['weighted_recall'].mean(),\n",
    "    \"recall@5\": df['recall@5'].mean(), \n",
    "    \"ndcg\": df['ndcg'].mean(),\n",
    "    \"ask_turn\": df['ask_turn'].mean(),\n",
    "    \"dont_know_num\": df['dont_know_num'].mean(),\n",
    "    \"rouge\": df['rouge'].mean(),\n",
    "    \"bertscore\": df['bertscore'].mean()\n",
    "}\n",
    "\n",
    "# 打印成表格形式\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}\\t{value:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 打印成一行,方便复制到Excel\n",
    "print(\"\\nExcel Format:\")\n",
    "print(\"\\t\".join([f\"{value:.4f}\" for value in metrics.values()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6a137e-130f-4982-a8b1-686981c6d91f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-14T03:22:24.082662Z",
     "iopub.status.busy": "2025-05-14T03:22:24.082092Z",
     "iopub.status.idle": "2025-05-14T03:22:24.086724Z",
     "shell.execute_reply": "2025-05-14T03:22:24.086112Z",
     "shell.execute_reply.started": "2025-05-14T03:22:24.082638Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "专业性 5.922972972972973\n",
      "流畅性 7.302702702702702\n",
      "完整性 5.2337837837837835\n",
      "服务性 5.5864864864864865\n",
      "安全性 7.120270270270271\n",
      "综合得分 5.944594594594594\n"
     ]
    }
   ],
   "source": [
    "for key in df.columns[-6:]:\n",
    "    print(key,df[key].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80135e8-5a60-48fc-b4e8-4cf5315e6c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb735d33-147b-4d55-9fad-5aced37c3bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78bcf9bb-449e-4179-a119-317c5df2b671",
   "metadata": {},
   "source": [
    "# See all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e492470-05ed-4c24-9d2e-c824032c7682",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-05-10T16:00:18.443807Z",
     "iopub.status.busy": "2025-05-10T16:00:18.442851Z",
     "iopub.status.idle": "2025-05-10T16:00:23.986999Z",
     "shell.execute_reply": "2025-05-10T16:00:23.986332Z",
     "shell.execute_reply.started": "2025-05-10T16:00:18.443782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path_li = [i for i in os.listdir(\"./outputs/evaluation_output/\") if \"_evalgpt42\" in i]\n",
    "# path_li\n",
    "\n",
    "res_ = []\n",
    "for p in path_li:\n",
    "    df = pd.read_csv(f\"./outputs/evaluation_output/{p}\")\n",
    "    \n",
    "    res_.append([p.replace(\"output_file_\",\"\").replace(\"_eval.csv\",\"\"),\n",
    "df['llm_evaluate_keyfact_recall'].mean(),df['weighted_recall'].mean(),\n",
    "    df['recall@5'].mean(), df['ndcg'].mean(),df['ask_turn'].mean(),df['dont_know_num'].mean(),\n",
    "    df['rouge'].mean(),df['bertscore'].mean(),\n",
    "    df['专业性'].mean(), df['流畅性'].mean(), df['完整性'].mean(), df['服务性'].mean(), df['安全性'].mean(), df['综合得分'].mean()          ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
